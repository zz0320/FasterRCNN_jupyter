{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Proposal生成和网络训练.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPLmog3FkwHAey4Y5LydQl2"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# model/utils/creator_tool.py文件 \n","\n","这个脚本实现了三个Creator函数，分别是：\n","\n","ProposalCreator\n","\n","AnchorTargetCreator\n","\n","ProposalTargetCreator\n","\n","前两个都在RPN网络里实现，第三个在RoIHead网络里实现\n","\n"],"metadata":{"id":"bdi-shdPcy0W"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"JrvhCm_Ub7N6"},"outputs":[],"source":["class ProposalCreator:\n","  \"\"\"\n","  对于每张图片，利用它的feature map 计算(H/16) * (W/16) * 9大概 20000个anchro属于前景的概率\n","  然后从中选取概率较大的12000张，利用位置回归参数，修正这12000个anchor的位置\n","  利用NMS 选出2000个ROIs以及对应的位置参数\n","  \"\"\"\n","\n","  def __init__(self,\n","               parent_model,\n","               n_train_pre_nms=12000,\n","               n_train_post_nms=2000,\n","               n_test_pre_nms=6000,\n","               n_test_post_nms=300,\n","               min_size=16):\n","    self.parent_model = parnet_model\n","    self.nms_thresh = nms.thresh\n","    self.n_train_pre_nms = n_train_pre_nms\n","    self.n_train_post_nms = n_train_post_nms\n","    self.n_test_pre_nms = n_test_pre_nms\n","    self.n_test_post_nms = n_test_post_nms\n","    self.min_size = min_size\n","\n","  def __call__(self, loc, score,\n","               anchor, img_size, scale=1):\n","    # 这里的loc和score是经过RPN中经过1*1conv分类和回归得到的\n","    if self.parent_model.training: #如果是训练模式就用train 否则用test\n","      n_pre_nms = self.n_train_pre_nms #NMS之前有12000个\n","      n_post_nms = self.n_train_post_nms #NMS之后有2000个\n","    else:\n","      n_pre_nms = self.n_test_pre_nms # 6000->300\n","      n_post_nms = self.n_test_post_nms\n","\n","    # 把anchor转成proposal 即rois\n","    roi = loc2bbox(anchor,loc)\n","\n","    # Clip predicted boxes to images.\n","    roi[:, slice(0,4,2)] = np.clip(\n","        roi[:,slice(0,4,2)],0,img_size[0]) #裁剪将rois的ymin,ymax限定在[0,H]\n","    roi[:, slice(1,4,2)] = np.clip(\n","        roi[:,slice(1,4,2)],0,img_size[1]) #裁剪将rois的xmin,xmax限定在[0,W]\n","\n","    #去除太小的预测框\n","    min_size = self.min_size * scale #16\n","    hs = roi[:,2] - roi[:,0] #rois的宽\n","    ws = roi[:,3] - roi[:,1] #rois的长\n","    keep = np.where((hs >= min_size) & (ws >= min_size))[0] #确保rois的长宽大于最小阈值\n","    roi = roi[keep,:] \n","    score = score[keep] #对剩下的ROIs进行打分（根据RPN中ROIS的前景预测概率）\n","\n","    # 对所有的proposal,score按打分大小 从大到小\n","    # 选择最前面的pre_nms_TopN个(6000)\n","    order = score.ravel().argsort()[::-1]\n","    if n_pre_nms > 0:\n","      order = order[:n_pre_nms]\n","    roi = roi[order,:]\n","    score = score[order]\n","\n","\n","    #使用NMS,选择after_nms_topN\n","    keep = nms(\n","        torch.from_nmpy(roi).cuda()\n","        torch.from_numpy(score).cuda()\n","        self.nms_thresh)\n","    if n_post_nms > 0:\n","      keep keep[:n_post_nms]\n","    roi = roi[keep.cpu().numpy()]\n","    return roi\n"]},{"cell_type":"code","source":["class AnchorTargetCreator(object):\n","  \"\"\" \n","  作用是生成训练要用的anchro（与对应框iou值最大或者最小的各128个框的坐标和256个label（0或者1））\n","  为Faster R-CNN专有的RPN网络提供自我训练的样本，RPN网络正是利用AnchorTargetCreator产生的样本数据进行训练\n","  这样产生的预测anchor的类别和位置才更加精准， anchor变成真正的ROIS需要进行位置矫正\n","  而AnchorTargetCreator产生的带标签的样本就是给RPN网络进行训练学习用的\n","  \"\"\"\n","  def __init__(self,\n","               n_sample=256,\n","               pos_iou_thresh=0.7,neg_iou_thresh=0.3,\n","               pos_ratio=0.5):\n","    self.n_sample = n_sample\n","    self.pos_iou_thresh = pos_iou_thresh\n","    self.neg_iou_thresh = neg_iou_thresh\n","    self.pos_ratio = pos_ratio\n","\n","  def __call__(self, bbox, anchor, img_size):\n","\n","    img_H, img_W = img_size\n","\n","    n_anchor = len(anchor) #一般对应20000个左右anchor\n","    inside_index = _get_inside_index(anchor, img_H, img_W) #将那些超出图片范围的anchor全部去掉，只保留位于图片上的\n","    anchor = anchor[inside_index] #保留位于图片内部的anchor\n","    argmax_ious, label = self._create_label(\n","        inside_index, anchor, bbox) #筛选出符合条件的正例128个 负例128个 并给它们附上对应的label\n","    # 计算每一个anchor与对应bbox求得iou最大的bbox计算偏移量（注意这里是位于图片内部的每一个）\n","    loc = bbox2loc(anchor, bbox[argmax_ious]) \n","    # 将位于图片内部的框的label对应到所有生成的20000个框中（label原本为所有图片中的框的）\n","    label = _unmap(label, n_anchor, inside_index, fill=-1)\n","    # 将回归的框对应到所有生成的20000个框中（label原本为所有在图片中的框的）\n","    loc = _unmap(loc, n_anchor, inside_index, fill=0)\n","\n","    return loc, label\n","\n","  def _create_label(self, inside_index, anchor, bbox):\n","    # label: 1 is pos; 0 is neg; -1 is dont care\n","    label = np.empty((len(inside_index), dtype=np.int32))\n","    label.fill(-1) # 全部填充-1\n","    # 调用_calc_ious()函数得到每个anchor与哪个bbox的iou最大以及这个iou值、每个bbox与哪个anchor的iou最大\n","    argmax_ious, max_ious, gt_argmax_ious = \\\n","      self._calc_ious(anchor, bbox, inside_index)\n","\n","    # 把每个anchor与对应的框求得的iou值与负样本阈值比较 若小于负样本阈值，\n","    # 则label设为0， pos_iou_thresh=0.7 neg_iou_thresh=0.3\n","    label[max_ious < self.neg_iou_thresh] = 0\n","\n","    # 把与每个bbox求得iou值最大的anchor的label设为1\n","    label[gt_argmax_ious] = 1\n","\n","    # 把每个anchor与对应的框求得的iou值与正样本阈值比较，若大于正样本阈值，则label=1\n","    label[max_ious >= self.pos_iou_thresh] = 1\n","\n","    # 按照比例计算出正样本数量，pos_ratio=0.5, n_sample=256\n","    n_pos = int(self.pos_ratio * self.n_sample)\n","    pos_index = np.where(label == 1)[0] # 得到所有正样本的索引\n","    if len(pos_index) > n_pos:\n","      disable_index = np.random.choice(\n","          pos_index, size = (len(pos_index) - n.pos),replace=False)\n","      label[disable_index] = -1 #如果选出来的正样本数多于预设的正样本数 则随机抛弃的设定成-1\n","\n","    # 设定的负样本的数量\n","    n_neg = self.n_sample - np.sum(label == 1)\n","    neg_index = np.where(label == 0)\n","    if len(neg_index) > n_neg:\n","      disable_index = np.random.choice(\n","          neg_index, size = (len(neg_index) - n_neg),replace=False)\n","      label[disable_index] = -1 #随机选择不需要的负样本，个数为len(neg_index)-neg_index,labe设定为-1\n","\n","\n","    return argmax_ious, label\n","\n","  def _calc_ious(self, anchor, bbox, inside_index):\n","    # 调用bbox_iou函数计算anchor与bbox的IOU, ious:(N,K) N为anchor中第N个，K为bbox中第K个\n","    ious = bbox_iou(anchor, bbox)\n","    argmax_ious = ious.argmax(axis=1)\n","    # 求出每个anchor与哪个bbox的IoU最大，以及最大值，max_ious:[1,N]\n","    max_ious = ious[np.arange(len(inside_index)),argmax_ious]\n","    gt_argmax_ious = ious.argmax(axis=0)\n","    # 求出每个bbox与哪个anchor的IoU最大，以及最大值，gt_max_ious:[1,K]\n","    gr_max_ious = ious[gt_argmax_ious, np.arange(ious.shape[1])]\n","    gt_argmax_ious = np.where(ious == gt_max_ious)[0] #然后返回最大iou的索引（每个bbox与哪个anchor的iou最大）\n","\n","    return argmax_ious, max_ious, gt_argmax_ious"],"metadata":{"id":"EuCtRTLwmEpq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["下面是ProposalTargetCreator的代码\n","\n","目的：为2000个rois赋予ground truth 严格讲是挑出128个赋予ground truth\n","\n","输入：2000个rois、一个batch（一张图）中所有的bbox ground truth (R,4)、对应bbox所包含的label(R,1) （VOC2007来说20类 0-19）\n","\n","输出：128个sample roi(128,4)、128个gt_roi_loc(128,4)、128个gt_roi_label(128,1)\n"],"metadata":{"id":"VbFGuuEyuTLl"}},{"cell_type":"code","source":["class ProposalCreator(object):\n","  \"\"\"\n","  为2000个rois赋予ground truth\n","  输入：2000个rois、一个batch中所有的bbox ground truth（R，4）、对应bbox所包含的label（R，1）\n","  输出：128个sample roi（128，4）、128个gt_roi_loc(128,4)、128个gt_roi_label(128,1)\n","  \"\"\"\n","  def __init__(self,\n","               n_sample=128,\n","               pos_ratio=0.25,pos_iou_thresh=0.5,\n","               neg_iou_thresh_hi=0.5, neg_iou_thresh_lo=0.0):\n","    self.n_sample = n_sample\n","    self.pos_ratio = pos_ratio\n","    self.pos_iou_thresh = pos_iou_thresh\n","    self.neg_iou_thresh_hi = neg_iou_thresh_hi\n","    self.neg_iou_thresh_lo = neg_iou_thresh_lo # NOTE:default 0.1 in py-faster-rcnn\n","\n","  def __call__(self,roi,bbox,label,\n","               loc_normalize_mean=(0,0,0,0),\n","               loc_normalize_std=(0.1,0.2,0.2)):\n","    # 因为这些数据是要放入最后的大网络进行训练，比如说位置数据，所以要对其位置坐标进行数据增强处理 归一化\n","    n_bbox,_ = bbox.shape\n","    n_bbox,_ = bbox.shape\n","\n","    roi = np.concatenate((roi,bbox), axis=0)# 首先将2000个roi和m个bbox给concatenate了一下成为新的roi\n","    # n_sample = 128, pos_ratio = 0.5, round 对传入的数据进行四舍五入\n","    pos_roi_per_image = np.round(self.n_sample * self.pos_ratio)\n","    iou = bbox_iou(roi, bbox) # 计算每一个roi与每一个bbox的iou\n","    # 按行找到最大值， 返回最大值对应的序号以及其真正的IoU\n","    gt_assignment = iou.argmax(axis=1)\n","    max_iou = iou.max(axis=1) #每个roi与对应bbox最大的iou\n","    # Offset range of classes from [0, n_fg_class-1] to [1, n_fg_class].\n","    # 0是背景\n","    gt_roi_label = label[gt_assignment] + 1 # 从1开始的类别序号，给每个类得到真正的label(将0-19变成1-20)\n","\n","    # 根据iou的最大值将正负样本找出来 pos_iou_thresh=0.5\n","    pos_index = np.where(max_iou>=self.pos_iou_thresh)[0]\n","    # 需要保留的roi个数（满足大于pos_iou_thresh条件的roi与64之间较小的一个）\n","    pos_roi_per_this_image = int(main(pos_roi_per_image,pos_index.size))\n","    if pos_index.size > 0:\n","      pos_index = np.random.choice(\n","          pos_index,size=pos_roi_per_this_image,replace=False) #找出的样本数目过多就随机丢掉一些\n","\n","    # 负样本的ROI区间[neg_iou_thresh_lo, neg_iou_thresh_hi]\n","    # neg_iou_thresh_hi = 0.5, neg_iou_thresh_li = 0.0\n","    neg_index = np.where((max_iou < self.neg_iou_thresh_hi)&\n","                (max_iou >= self.neg_iou_thresh_lo))[0]\n","    # 需要保留的roi个数 （满足大于0小于neg_iou_thresh_hi条件的roi与64之间较小的一个）\n","    neg_roi_per_this_image = self.n_sample - pos_roi_per_this_image\n","    neg_roi_per_this_image = int(min(neg_roi_per_this_image,\n","                                     neg_index.size))\n","    if neg_index.size > 0:\n","      neg_index = np.random.choice(\n","          neg_index,size=neg_roi_per_this_image,replace=False) #找出的样本数目过多就随机丢掉一些\n","\n","    # 综合下找到的正负样本的index\n","    keep_index = np.append(pos_index, neg_index)\n","    gt_roi_label = gt_roi_label[keep_index]\n","    gt_roi_label[pos_roi_per_this_image:] = 0 #负样本label 设为0\n","    sample_roi = roi[keep_index] \n","\n","    \"\"\"\n","    那么此时输出的128*4的sample_roi就可以去扔到RoIHead网络里去进行分类与回归了\n","    同样，RoIHead网络利用这sample_roi + feature为输入，输出是分类（21类）和回归（进一步微调bbox）的预测值\n","    那么分类回归的ground truth就是ProposalTargetCreator输出的gt_roi_label和gt_roi_loc\n","    \"\"\"\n","    gt_roi_loc = bbox2loc(sample_roi, bbox[gt_assignment[keep_index]])\n","    gt_roi_loc = ((gt_roi_loc - np.array(loc_normalize_mean, np.float32)\n","              ) / np.array(loc_normalize_std, np.float32))\n","    \n","    # ProposalTargetCreator首次用到了真实的21个类的label，且该类最后对loc进行了归一化处理，所以预测时要进行均值方差归一化处理\n","\n","    return sample_roi, gt_roi_loc, gt_roi_label"],"metadata":{"id":"8oXKmZHsmjgf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Trainer.py"],"metadata":{"id":"Rc5QVKJDDFEd"}},{"cell_type":"code","source":["class FasterRCNNTrainer(nn.Module):\n","\n","  def __init__(self, faster_rcnn):\n","    super(FasterRCNNTrainer, self).__init__()\n","\n","    self.faster_rcnn = faster_rcnn\n","    self.rpn_sigma = opt.rpn_sigma\n","    self.roi_sigma = opt.roi_sigma\n","\n","    self.anchor_target_creator = AnchorTargetCreator()\n","    self.proposal_target_creator = ProposalCreator()\n","    self.loc_normalize_mean = faster_rcnn.loc_normalize_mean\n","    self.loc_normalize_std = faster_rcnn.loc_normalize_std\n","\n","    self.optimizer = self.faster_rcnn.get_opetimizer()\n","    self.vis = Visualizer(env=opt.env)\n","\n","    self.rpn_cm = ConfusionMeter(2)\n","    self.roi_cm = ConfusionMeter(21)\n","    self.meters = {k:AverageValueMeter() for k in LossTuple._fields}\n","\n","  def forward(self,img,bboxes, labels,scale):\n","    n = bboxes.shape[0] # 获取batch个数\n","    if n!= 1:\n","      raise ValueError('Currently only batch size 1 is supported')\n","    _,_,H,W = img.shape\n","    img_size = (H,W)\n","\n","    features = self.faster_rcnn.extractor(imgs) #vgg16 conv5_3之前的部分提取图片的特征\n","    # 通过RPN提取ROI相关的信息\n","    rpn_loc, rpn_scores, rois, roi_indices, anchor = \\\n","      self.faster_rcnn.rpn(features, img_size, scale)\n","\n","    bbox = bboxes[0]\n","    label = labels[0]\n","    rpn_score = rpn_scores[0]\n","    rpn_loc = rpn_locs[0]\n","    roi = rois\n","    # 调用proposal_target_creator函数生成sample_roi(128,4) / gt_roi_loc(128,4) / gt_roi_label(128,1)\n","    # RoIHead网络利用sample_roi + feature为输入 输出是分类 和 回归的预测值\n","    # 那么分类回归的ground truth就是ProposalTargetCreator输出的gt_roi_label和gt_roi_lic\n","    sample_roi, gt_roi_loc, gt_roi_label = self.proposal_target_creator(\n","      roi,\n","      at.tonumpy(bbox),\n","      at.tonumpy(label),\n","      self.loc_normalize_mean,\n","      self.loc_normalize_std)\n","    \n","    sample_roi_index = t.zeros(len(sample_roi))\n","    roi_cls_loc, roi_score = self.faster_rcnn.head(\n","        features,\n","        sample_roi,\n","        sample_roi_index)\n"," # ------------------ RPN losses -------------------#\n","    gt_rpn_loc, gt_rpn_label = self.anchor_target_creator(\n","        at.tonumpy(bbox),\n","        anchor,\n","        img_size) # 输入20000个anchor和bbox，调用anchor_target_creator函数得到2000个anchor和bbox的偏移量与label\n","    gt_rpn_label = at.totensor(gt_rpn_label).long()\n","    gt_rpn_loc = at.totensor(gt_rpn_loc)\n","    rpn_loc_loss = _fast_rcnn_loc_loss(\n","        rpn_loc,\n","        gt_rpn_loc,\n","        gt_rpn_label.data,\n","        self.rpn_sigma) #使用smooth_l1_loss\n","    #rpn_loc为rpn网络回归出来的偏移量(20000个)\n","    #gt_rpn_loc为anchor_target_creator函数得到2000个anchor与bbox的偏移量,rpn_sigma=1\n","\n","    #rpn_score为rpn网络得到的20000个与anchor_target_creator得到的2000个label求交叉熵损失\n","    rpn_cls_loss = F.cross_entropy(rpn_score, gt_rpn_label.cuda(), ignore_index=-1)\n","    _gt_rpn_label = gt_rpn_label[gt_rpn_label > -1] # 在rpn不计算背景类\n","    rpn_score = at.tonumpy(rpn_score)[at.tonumpy(gt_rpn_label) > -1]\n","    self.rpn_cm.add(at.totensor(_rpn_score, False), _gt_rpn_label.data.long())\n","\n","# ------------------ ROI losses (fast rcnn loss) -------------------#\n","    # roi_cls_loc为VGG16RoIHead的输出（128*84） n_sample=128\n","    n_sample = roi_cls_loc.shape[0]\n","    roi_cls_loc = roi_cls_loc.view(n_sample, -1, 4) # roi_cls_loc = (128, 21, 4)\n","    roi_loc = roi_cls_loc[t.arange(0, n_sample).long().cuda(), \\\n","                          at.totensor(gt_roi_label).long()]\n","    gt_roi_label = at.totensor(gt_roi_label).long()\n","    gt_roi_loc = at.totensor(gt_roi_loc) #128个标签\n","\n","    roi_loc_loss = _fast_rcnn_loc_loss(\n","        roi_loc.contiguous(),\n","        gt_roi_loc,\n","        gt_roi_label.data,\n","        self.roi_sigma) # 采用smooth_l1_loss\n","\n","    roi_cls_loss = nn.CrossEntropyLoss()(roi_score, gt_roi_label.cuda())\n","\n","    self.roi_cm.add(at.totensor(roi_score, False), gt_roi_label.data.long())\n","\n","    losses = [rpn_loc_loss, rpn_cls_loss, roi_loc_loss, roi_cls_loss]\n","    losses = losses + [sum(losses)]\n","\n","    return LossTuple(*losses)\n","\n","def _smooth_l1_loss(x, t, in_weight, sigma):\n","    sigma2 = sigma ** 2\n","    diff = in_weight * (x - t)\n","    abs_diff = diff.abs()\n","    flag = (abs_diff.data < (1. / sigma2)).float()\n","    y = (flag * (sigma2 / 2.) * (diff ** 2) +\n","         (1 - flag) * (abs_diff - 0.5 / sigma2))\n","    return y.sum()\n","\n","def _fast_rcnn_loc_loss(pred_loc, gt_loc, gt_label, sigma):\n","    # 输入分别为rpn回归框的偏移量与anchor与bbox的偏移量以及label\n","    in_weight = t.zeros(gt_loc.shape).cuda()\n","    in_weight[(gt_label > 0).view(-1, 1).expand_as(in_weight).cuda()] = 1\n","    loc_loss = _smooth_l1_loss(pred_loc, gt_loc, in_weight.detach(), sigma)\n","    # Normalize by total number of negtive and positive rois.\n","    loc_loss /= ((gt_label >= 0).sum().float())\n","     # ignore gt_label==-1 for rpn_loss 去除背景类\n","    return loc_loss\n","\n","\n","    \n","\n","    \n"],"metadata":{"id":"IBNKrVQXDEtR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eEfS0TyZH-Tu","executionInfo":{"status":"ok","timestamp":1645461144296,"user_tz":-480,"elapsed":32657,"user":{"displayName":"陨石少校","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03845389283983531015"}},"outputId":"f2c654c9-bb4c-429c-e9b0-d9f84dc45bc4"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["# Train.py"],"metadata":{"id":"M8LoY8tFGHdh"}},{"cell_type":"code","source":["def train(**kwargs):\n","    opt._parse(kwargs)\n","\n","    dataset = Dataset(opt)\n","    print('load data')\n","    dataloader = data_.DataLoader(dataset, \\\n","                                  batch_size=1, \\\n","                                  shuffle=True, \\\n","                                  # pin_memory=True,\n","                                  num_workers=opt.num_workers)\n","    testset = TestDataset(opt)\n","    test_dataloader = data_.DataLoader(testset,\n","                                       batch_size=1,\n","                                       num_workers=opt.test_num_workers,\n","                                       shuffle=False, \\\n","                                       pin_memory=True\n","                                       )\n","    faster_rcnn = FasterRCNNVGG16()\n","    print('model construct completed')\n","    # 设置trainer = FasterRCNNTrainer(faster_rcnn).cuda()\n","    # 将fasterRCNNVGG16作为fasterrcnn的模型送入到FasterRCNNTrainer中并设置好GPU加速\n","    trainer = FasterRCNNTrainer(faster_rcnn).cuda()\n","    if opt.load_path: #预训练模型\n","        trainer.load(opt.load_path)\n","        print('load pretrained model from %s' % opt.load_path)\n","    trainer.vis.text(dataset.db.label_names, win='labels')\n","    best_map = 0\n","    lr_ = opt.lr\n","\n","    #用一个for循环开始训练过程 epoch为超参数\n","    for epoch in range(opt.epoch):\n","        trainer.reset_meters()\n","        for ii, (img, bbox_, label_, scale) in tqdm(enumerate(dataloader)):\n","            scale = at.scalar(scale)\n","            img, bbox, label = img.cuda().float(), bbox_.cuda(), label_.cuda()\n","            # 从训练数据中枚举dataloader 设置好缩放范围，将img,bbox,label,scale全部设置为可GPU加速\n","            trainer.train_step(img, bbox, label, scale)\n","            #调用trainer.py中的函数trainer.train_step(img,bbox,label,scale)进行一次参数迭代优化过程\n","\n","            if (ii + 1) % opt.plot_every == 0:\n","                if os.path.exists(opt.debug_file):\n","                    ipdb.set_trace()\n","\n","                # plot loss\n","                trainer.vis.plot_many(trainer.get_meter_data())\n","\n","                # plot groud truth bboxes\n","                ori_img_ = inverse_normalize(at.tonumpy(img[0]))\n","                gt_img = visdom_bbox(ori_img_,\n","                                     at.tonumpy(bbox_[0]),\n","                                     at.tonumpy(label_[0]))\n","                trainer.vis.img('gt_img', gt_img)\n","\n","                # plot predicti bboxes\n","                _bboxes, _labels, _scores = trainer.faster_rcnn.predict([ori_img_], visualize=True)\n","                pred_img = visdom_bbox(ori_img_,\n","                                       at.tonumpy(_bboxes[0]),\n","                                       at.tonumpy(_labels[0]).reshape(-1),\n","                                       at.tonumpy(_scores[0]))\n","                trainer.vis.img('pred_img', pred_img)\n","\n","                # rpn confusion matrix(meter)\n","                trainer.vis.text(str(trainer.rpn_cm.value().tolist()), win='rpn_cm')\n","                # roi confusion matrix\n","                trainer.vis.img('roi_cm', at.totensor(trainer.roi_cm.conf, False).float())\n","        eval_result = eval(test_dataloader, faster_rcnn, test_num=opt.test_num)\n","        trainer.vis.plot('test_map', eval_result['map'])\n","        lr_ = trainer.faster_rcnn.optimizer.param_groups[0]['lr']\n","        log_info = 'lr:{}, map:{},loss:{}'.format(str(lr_),\n","                                                  str(eval_result['map']),\n","                                                  str(trainer.get_meter_data()))\n","        trainer.vis.log(log_info)\n","\n","        if eval_result['map'] > best_map:\n","            best_map = eval_result['map']\n","            best_path = trainer.save(best_map=best_map)\n","        if epoch == 9:\n","            trainer.load(best_path)\n","            trainer.faster_rcnn.scale_lr(opt.lr_decay)\n","            lr_ = lr_ * opt.lr_decay # 这里有一个lr_decay epoch到了9 lr就*0.1\n","\n","        if epoch == 13: \n","            break"],"metadata":{"id":"I0qwGm67DgYO"},"execution_count":null,"outputs":[]}]}